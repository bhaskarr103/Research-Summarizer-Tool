{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Static vs Dynamic Output in LLMs and Streamlit Apps**\n",
    "\n",
    "When working with **language models (LLMs)** or **Streamlit applications**, understanding **static vs. dynamic output** is crucial.\n",
    "\n",
    "---\n",
    "\n",
    "## **🔹 1. Static Output**\n",
    "A **static output** is **predefined** and does not change based on user input or runtime conditions.  \n",
    "- **Fixed response**\n",
    "- **No real-time computation**\n",
    "- **Same output every time for a given input**\n",
    "\n",
    "### **🛠 Example of Static Output**\n",
    "```python\n",
    "import streamlit as st\n",
    "\n",
    "st.header(\"Static Output Example\")\n",
    "\n",
    "st.write(\"This is a predefined static response. It remains unchanged.\")\n",
    "```\n",
    "📌 **No matter what the user inputs, the output remains the same.**  \n",
    "\n",
    "---\n",
    "\n",
    "## **🔹 2. Dynamic Output**\n",
    "A **dynamic output** is **generated in real-time** based on user input, model inference, or other external factors.  \n",
    "- **Changes with input**\n",
    "- **Generated at runtime**\n",
    "- **Interactive and flexible**\n",
    "\n",
    "### **🛠 Example of Dynamic Output (LLM Integration)**\n",
    "```python\n",
    "import streamlit as st\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HUGGINGFACEHUB_ACCESS_TOKEN\")\n",
    "\n",
    "# Load LLM model\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=hf_token,\n",
    "    max_new_tokens=50\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# Streamlit UI\n",
    "st.header(\"Dynamic Output Example\")\n",
    "\n",
    "user_input = st.text_input(\"Enter your prompt\")\n",
    "\n",
    "if st.button(\"Generate Response\"):\n",
    "    with st.spinner(\"Thinking...\"):\n",
    "        result = model.invoke(user_input)\n",
    "        st.write(result.content if hasattr(result, \"content\") else result)\n",
    "```\n",
    "📌 **Here, the output depends on the user's input, making it dynamic.**\n",
    "\n",
    "---\n",
    "\n",
    "## **🔹 Key Differences: Static vs Dynamic**\n",
    "| Feature          | Static Output | Dynamic Output |\n",
    "|-----------------|--------------|--------------|\n",
    "| **User Input**   | Not required | Required |\n",
    "| **Changes at Runtime?** | ❌ No | ✅ Yes |\n",
    "| **Predefined?** | ✅ Yes | ❌ No |\n",
    "| **Computation Needed?** | ❌ No | ✅ Yes |\n",
    "| **Examples** | `st.write(\"Hello!\")` | AI-generated response, real-time calculations |\n",
    "\n",
    "---\n",
    "\n",
    "### **🎯 When to Use What?**\n",
    "✔ **Static Output:** Use when content does not change (e.g., instructions, headers, static text).  \n",
    "✔ **Dynamic Output:** Use when output varies (e.g., chatbot, summarization, AI-generated responses).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Prompts Blue Print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please summarize the research paper titled \"{paper_input}\" with the following specifications:**  \n",
    "\n",
    "**Explanation Style:** {style_input}  \n",
    "**Explanation Length:** {length_input}  \n",
    "\n",
    "1. **Mathematical Details:**  \n",
    "   - Include relevant mathematical equations if present in the paper.  \n",
    "   - Explain the mathematical concepts using simple, intuitive code snippets where applicable.  \n",
    "\n",
    "2. **Analogies:**  \n",
    "   - Use relatable analogies to simplify complex ideas.  \n",
    "\n",
    "If certain information is not available in the paper, respond with:  \n",
    "*\"Insufficient information available\"* instead of guessing.  \n",
    "\n",
    "Ensure the summary is clear, accurate, and aligned with the provided style and length.  \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
